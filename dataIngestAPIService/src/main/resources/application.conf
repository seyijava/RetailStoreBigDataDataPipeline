

akka {
  # Log the complete configuration at INFO level when the actor system is started.
  # This is useful when you are uncertain of what configuration is used.
  log-config-on-start = off

  # stdout-loglevel = "OFF"
  stdout-loglevel = "INFO"
  # loglevel = "OFF"
  loglevel = "INFO"
  #loggers = ["akka.event.slf4j.Slf4jLogger"]
  #logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  log-dead-letters = on
  log-dead-letters-during-shutdown = off
  }

######################################
# Kafka Configuration
######################################

akka.kafka.producer{
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 100

  # Duration to wait for `KafkaProducer.close` to finish.
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  # for exactly-once-semantics processing.
  eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {

     bootstrap.servers = "127.0.0.1:9092"
  }
}


######################################
# App Configuration
######################################
rest
{
     host = "127.0.0.1"
     host = ${?SERVER_IP}

     port = "9000"
     port = ${?SERVER_PORT}
}

kafka{

 brokerUrl = "127.0.0.1:9092"
 brokerUrl = ${?KAFKA_SERVER}

 dataIngestTopic = "DailyStoreTopic"
 dataIngestTopic = ${?kAFKA_DATAINGEST_TOPIC}

 partition = "S-001=0&S-002=1&S-003=2"

 partition-size=20
}

